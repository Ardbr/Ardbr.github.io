<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>flow_matching Ch01 | creat's HomePage</title><meta name="author" content="creat"><meta name="copyright" content="creat"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Flow Matching 总览 生成模型的目标 生成模型（GAN, VAE, Diffusion, Flow）的目标是已知样本 \(x_1 \sim q_1\) (未知)，用样本把未知分布估计出来。其中 \(x_1\) 代表真实数据（比如一张真实的狗的照片）。\(q_1\) 代表真实数据的分布（Data Distribution），这是上帝视角的分布，我们在数学上不知道它的解析式，但我们有从中采">
<meta property="og:type" content="article">
<meta property="og:title" content="flow_matching Ch01">
<meta property="og:url" content="https://ardbr.github.io/2026/02/12/notes/flow_matching/flow-matching-Ch01/index.html">
<meta property="og:site_name" content="creat&#39;s HomePage">
<meta property="og:description" content="Flow Matching 总览 生成模型的目标 生成模型（GAN, VAE, Diffusion, Flow）的目标是已知样本 \(x_1 \sim q_1\) (未知)，用样本把未知分布估计出来。其中 \(x_1\) 代表真实数据（比如一张真实的狗的照片）。\(q_1\) 代表真实数据的分布（Data Distribution），这是上帝视角的分布，我们在数学上不知道它的解析式，但我们有从中采">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ardbr.github.io/img/avatar.gif">
<meta property="article:published_time" content="2026-02-12T03:37:35.000Z">
<meta property="article:modified_time" content="2026-02-15T02:43:06.395Z">
<meta property="article:author" content="creat">
<meta property="article:tag" content="Flow Matching">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ardbr.github.io/img/avatar.gif"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ardbr.github.io/2026/02/12/notes/flow_matching/flow-matching-Ch01/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":10,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":false,"highlightMacStyle":"mac"},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'flow_matching Ch01',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/cursor.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_4746832_eb25gdpzci6.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/background.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.gif" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories"><i class="fa-fw fas fa-book"></i><span> 学习资料</span></a></div><div class="menus_item"><a class="site-page" href="/link"><i class="fa-fw fas fa-globe"></i><span> 常用网站</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/favicon.png" alt="Logo"><span class="site-name">creat's HomePage</span></a><a class="nav-page-title" href="/"><span class="site-name">flow_matching Ch01</span></a></span><div id="music-bar"><div id="music-cover-container"><div id="music-cover"></div></div><div id="music-button-container"><div id="music-button-container-top"><span class="music-icon iconfont icon-shangyishou" id="music-prev"></span><span class="music-icon iconfont icon-bofang" id="music-playOrPause"></span><span class="music-icon iconfont icon-xiayishou" id="music-next"></span><span class="music-icon iconfont icon-liebiaoxunhuan" id="music-mode"></span></div><div id="music-button-container-bottom"><div id="music-progressBar"><span id="music-currentProgress"></span><span id="music-dot"></span></div><span id="music-progressText">00:00 / 00:00</span></div></div><div id="music-name-container"><span id="music-name"></span></div><div id="music-lyric-container"><span id="music-lyric"></span></div></div><div id="menus"><div id="toggle-menu"><span class="site-page"></span><i class="fas fa-bars fa-fw"></i></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories"><i class="fa-fw fas fa-book"></i><span> 学习资料</span></a></div><div class="menus_item"><a class="site-page" href="/link"><i class="fa-fw fas fa-globe"></i><span> 常用网站</span></a></div></div><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav><div id="post-info"><h1 class="post-title">flow_matching Ch01</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-02-12T03:37:35.000Z" title="发表于 2026-02-12 11:37:35">2026-02-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-15T02:43:06.395Z" title="更新于 2026-02-15 10:43:06">2026-02-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/notes/">notes</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/notes/flow-matching/">flow_matching</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="flow-matching-总览">Flow Matching 总览</h2>
<h3 id="生成模型的目标">生成模型的目标</h3>
<p>生成模型（GAN, VAE, Diffusion, Flow）的目标是已知样本 <span
class="math inline">\(x_1 \sim q_1\)</span>
(未知)，用样本把未知分布估计出来。其中 <span
class="math inline">\(x_1\)</span>
代表真实数据（比如一张真实的狗的照片）。<span
class="math inline">\(q_1\)</span> 代表真实数据的分布（Data
Distribution），这是上帝视角的分布，我们在数学上不知道它的解析式，但我们有从中采样出来的“样本”。</p>
<p>我们的目标就是通过有限的样本，训练一个模型去逼近这个未知的 <span
class="math inline">\(q_1\)</span>。</p>
<h3 id="做法">做法</h3>
<p>为了达到这个目的，通常的做法是利用已知分布（通常为高斯分布/标准正态分布）来映射到未知分布
<span class="math inline">\(q_1\)</span>，即： <span
class="math display">\[
q_0 \text{（已知分布）} \xrightarrow{\phi} q_1
\text{（待估计的未知分布）}
\]</span></p>
<p>其中 <span class="math inline">\(\phi\)</span> (Phi)
是一个映射函数（Mapping）。</p>
<div class="note success flat"><p>💡生成模型的本质就是寻找一个映射 <span
class="math inline">\(\phi\)</span>，它能把简单的噪声 <span
class="math inline">\(x_0\)</span> “推”成复杂的图像 <span
class="math inline">\(x_1\)</span>。</p>
</div>
<h3 id="两种求解路径">两种求解路径</h3>
<h4 id="normalizing-flow标准化流">Normalizing Flow（标准化流）</h4>
<p>这是早期的流模型（如 RealNVP,
Glow），利用了概率论中的变量变换公式（Change of Variables
Formula）。它要求映射函数必须是可逆的，而且要计算雅可比行列式（Jacobian
Determinant），这极大地限制了神经网络的结构设计。</p>
<h4 id="flow-matching流匹配">Flow Matching（流匹配）</h4>
<p>这是目前最前沿的方法。它不再强求计算雅可比行列式，而是借助<strong>常微分方程（ODE）</strong>来建模。</p>
<div class="timeline "><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>将 <span class="math inline">\(q_0\)</span> 和 <span
class="math inline">\(q_1\)</span> 为 ODE 的起点和终点</p>
</div></div><div class='timeline-item-content'><p>我们不再直接学映射，而是定义一个随时间 <span
class="math inline">\(t\)</span> 变化的路径（Probability Path），从噪声
<span class="math inline">\(t=0\)</span> 逐渐变成数据 <span
class="math inline">\(t=1\)</span>。</p>
</div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>用神经网络逼近 ODE 的导数项</p>
</div></div><div class='timeline-item-content'><p>这里的“导数项”就是向量场（Vector
Field），也就是数据移动的“速度”和“方向”。</p>
<p>这也是 Flow Matching
的核心：我们训练网络去预测在某个时刻，数据应该往哪个方向流。</p>
</div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>解 ODE, 得到 <span class="math inline">\(\varphi\)</span></p>
</div></div><div class='timeline-item-content'><p>训练好网络后，生成过程就是从噪声出发，沿着网络预测的“速度场”，一步步数值积分（比如用欧拉法），最终流向真实数据。</p>
</div></div></div>
<div class="note warning flat"><p>💥<strong>符号问题澄清</strong></p>
<hr />
<p>在 DDPM 中，通常 <span class="math inline">\(x_0\)</span>
是原始图，<span class="math inline">\(x_T\)</span> 是噪声。</p>
<p>而在 Flow Matching 中，通常 <span class="math inline">\(x_0\)</span>
是噪声（起点），<span class="math inline">\(x_1\)</span>
是图（终点）。这点符号上是反的，看的时候要注意。</p>
</div>
<h2 id="flow-定义">Flow 定义</h2>
<p>在不同的资料中，流有着不同的定义。但它们只是从<strong>“微观（微分）”</strong>和<strong>“宏观（积分）”</strong>两个不同视角来描述同一个物理过程。</p>
<h3 id="微观视角微分v_t">微观视角（微分）——<span
class="math inline">\(v_t\)</span></h3>
<p>这里将流定义为 <span class="math inline">\(v = \{v_t\}_{t \in [0,
1]}\)</span>。即一系列的向量场 (Vector Field) / 速度场 (Velocity
Field)。</p>
<p>它描述的是每一个瞬间、每一个位置上数据的“移动速度”和“方向”。这是我们在神经网络里直接去“学”（训练）的东西，<strong>网络输入
<span class="math inline">\((x, t)\)</span>，输出这个点的速度 <span
class="math inline">\(v_t(x)\)</span></strong>。</p>
<h3 id="宏观视角积分phi">宏观视角（积分）——<span
class="math inline">\(\phi\)</span></h3>
<p>这里将流定义为流映射 (Flow Map) / 轨迹。</p>
<p>它描述的是一个初始点 <span
class="math inline">\(\boldsymbol{x}_0\)</span> 随时间 <span
class="math inline">\(t\)</span>
移动后的最终位置或整条轨迹。这是我们通过解 ODE 算出来的结果。</p>
<h3 id="两者的等价关系">两者的等价关系</h3>
<p>我们假设初始噪声点为 <span
class="math inline">\(\boldsymbol{x}_0\)</span>，最终生成的干净数据为
<span class="math inline">\(\boldsymbol{x}_1\)</span>，数据的维度为
<span class="math inline">\(d\)</span> 维，即 <span
class="math inline">\(x_0 = (x^1, x^2, ..., x^d)\)</span>。则 <span
class="math inline">\(v_t\)</span> 与 <span
class="math inline">\(\phi\)</span> 都是 <span class="math inline">\([0,
1] \times \mathbb{R}^d \rightarrow \mathbb{R}^d\)</span>
的映射，且有公式 <span class="math inline">\(\ref{eq:flow_def1}\)</span>
成立。 <span class="math display">\[
\begin{equation}
\frac{\text{d} x_t}{\text{d} t} = v_t(x_t, t), \quad t \in [0, 1]
\label{eq:flow_def1}
\end{equation}
\]</span></p>
<div class="note danger flat"><p>注意这里的 <span class="math inline">\(v_t\)</span>
不仅与时间有关，还与当前时刻 <span class="math inline">\(t\)</span>
中每一个粒子的位置有关系。这里当时我理解起来有一些费解，因为 <span
class="math inline">\(v_t\)</span> 下标是 <span
class="math inline">\(t\)</span>，我就理所当然以为其只与 <span
class="math inline">\(t\)</span> 有关了，当然还受一直以来使用 2
维的轨迹微分是速度的影响。在我们 Flow
场景中，一般数据都是极高维的。相当于对于每一个像素点，我们都将其视作了一个
2 维点轨迹微分是速度进行求解。每一个像素点的速度场会不同，因此，<span
class="math inline">\(x_t\)</span> 也是要作为输入的。</p>
<p>在这里可以举一个浅显易懂的例子解释一下：我们要把一堆高斯噪声点（就像广场上聚集的一群人，每一个人就相当于是一个像素点）变成真实数据分布（让大家各自回家）。</p>
<p>起点 <span class="math inline">\(t=0\)</span>：所有人（噪声 <span
class="math inline">\(x\)</span>）都在广场中心聚集（标准正态分布）。</p>
<p>终点 <span class="math inline">\(t=1\)</span>：小明 (<span
class="math inline">\(x_A\)</span>) 的家在东边的北京。小红 (<span
class="math inline">\(x_B\)</span>) 的家在西边的伦敦。</p>
<p>如果 <span class="math inline">\(v_t\)</span> 只与 <span
class="math inline">\(t\)</span> 有关，不依赖于位置 <span
class="math inline">\(x\)</span>：这意味着在 <span
class="math inline">\(t=0.1\)</span>
时刻，广播里喊：“所有人往东走！”。结果：小明开心了，但小红也被迫往东走，最后大家都到了北京。这不仅没法生成多样的图像，还会把本来分散的分布强行平移。</p>
<p>因为 <span class="math inline">\(v_t\)</span> 依赖于位置 <span
class="math inline">\(x\)</span>：在这个场中，如果你站在东侧 (<span
class="math inline">\(x_A\)</span>)，你会感受到向东的风（速度 <span
class="math inline">\(v &gt; 0\)</span>）。如果你站在西侧 (<span
class="math inline">\(x_B\)</span>)，你会感受到向西的风（速度 <span
class="math inline">\(v &lt; 0\)</span>）。这样，同一个时刻 <span
class="math inline">\(t\)</span>，不同的位置有不同的指引，才能把一团原本聚集在一起的橡皮泥（噪声），捏成形状各异的雕塑（真实数据）。</p>
</div>
<p>此外，由定义可以有公式 <span
class="math inline">\(\ref{eq:xt_def}\)</span> 成立。 <span
class="math display">\[
\begin{equation}
x_t = \phi(x_0, t) \label{eq:xt_def}
\end{equation}
\]</span></p>
<p>将公式 <span class="math inline">\(\ref{eq:xt_def}\)</span> 代入到
<span class="math inline">\(\ref{eq:flow_def1}\)</span> 中，写出来就是：
<span class="math display">\[
\begin{align}
v_t(\phi_t(x_0, t), t) &amp;= \frac{\text{d} \phi_t(x_0, t)}{\text{d}t}
\label{eq:vt}\\
\phi_t(x_0, t) &amp;= \int_0^t v_t(\phi_t(x_0, \tau), \tau) \text{d}\tau
+ x_0 \quad \color{red}{\text{（两边进行积分）}} \label{eq:flow_def2}
\end{align}
\]</span></p>
<p>可以看到，公式 <span
class="math inline">\(\ref{eq:flow_def2}\)</span>
就是从宏观积分角度进行分析的，使用 <span
class="math inline">\(v\)</span> 或者 <span
class="math inline">\(\phi\)</span> 来看待流 flow
的定义，本质是等价的，一一对应的。</p>
<h2 id="连续性方程">连续性方程</h2>
<h3 id="连续性方程公式表达">连续性方程公式表达</h3>
<p>一种检验一个向量场 <span class="math inline">\(v_t(x)\)</span>
是否能够产生概率路径 <span class="math inline">\(p_t\)</span>
的方法是<strong>连续性方程</strong>。 <span class="math display">\[
\begin{equation}
\frac{d}{dt}p_t(x) + \text{div}(p_t(x)v_t(x)) = 0
\label{eq:continuity_eq}
\end{equation}
\]</span></p>
<p>我们可以把它移项变成更易懂的形式： <span class="math display">\[
\underbrace{\frac{d}{dt}p_t(x)}_{\text{密度的变化}} = \underbrace{-
\text{div}(p_t(x)v_t(x))}_{\text{流入量的净值}}
\]</span></p>
<h3 id="例子理解">例子理解</h3>
<p>我们可以通过一个直观的例子进行理解：想象你在一个拥挤的地铁站大厅（这是一个
<span class="math inline">\(d\)</span> 维空间）。</p>
<ul>
<li><span
class="math inline">\(p_t(x)\)</span>（概率密度）：大厅里某个位置 <span
class="math inline">\(x\)</span> 有多挤（人的密度）。</li>
<li><span
class="math inline">\(v_t(x)\)</span>（速度场）：这个位置的人群正在往哪个方向走，走得多快。</li>
</ul>
<p>连续性方程在说：人不会凭空消失，也不会凭空变出来（假设没有传送门）。如果你发现大厅里某一块区域（比如安检口）的人变得越来越多了（密度
<span class="math inline">\(\frac{d}{dt}p_t\)</span>
增加），那么一定是因为 <strong>走进这个区域的人</strong> 比
<strong>走出这个区域的人</strong> 多。这就是连续性方程的本质： <span
class="math display">\[
\text{密度的变化率} + \text{净流出量} = 0
\]</span></p>
<p>公式 <span class="math inline">\(\ref{eq:continuity_eq}\)</span>
的第一项 <span class="math inline">\(\frac{d}{dt}p_t(x)\)</span>
的含义：随着时间推移，在 <span class="math inline">\(x\)</span>
这个固定点，概率密度（拥挤程度）是变大了还是变小了？</p>
<p>第二项：<span class="math inline">\(\text{div}(p_t(x)v_t(x))\)</span>
这里是最难懂的，<span class="math inline">\(\text{div}\)</span>
是“发散算子” (Divergence)。<span
class="math inline">\(p_t(x)v_t(x)\)</span> 叫做通量 (Flux)。也就是“密度
<span class="math inline">\(\times\)</span>
速度”。它代表了<strong>“实际有多少量”</strong>在移动。</p>
<p><span class="math inline">\(\text{div}\)</span>
(散度)：它是在计算<strong>“向外扩散的程度”</strong>。</p>
<ul>
<li><span class="math inline">\(\text{div} &gt;
0\)</span>（正散度）：代表物质在向四周发散（像喷泉）。东西流走了，所以密度会下降。</li>
<li><span class="math inline">\(\text{div} &lt;
0\)</span>（负散度）：代表物质在向中心汇聚（像排水口）。东西流进来了，所以密度会上升。</li>
<li><span class="math inline">\(\text{div} =
0\)</span>：流进多少等于流出多少（像平滑的水管），密度不变。</li>
</ul>
<h3 id="连续性方程的作用">连续性方程的作用</h3>
<p>在 Flow Matching
中，这个方程起到了<strong>“桥梁”</strong>的作用。</p>
<ul>
<li>微观上：我们训练神经网络去预测每一个点的速度 <span
class="math inline">\(v_t(x)\)</span>（这是我们能控制的）。</li>
<li>宏观上：我们关心的是整张图片的分布 <span
class="math inline">\(p_t(x)\)</span> 如何从噪声变成真图。</li>
</ul>
<p>连续性方程告诉我们要如何检验：“如果你定义了速度场 <span
class="math inline">\(v_t\)</span>，那么概率分布 <span
class="math inline">\(p_t\)</span> <strong>必须且只能</strong>
按照连续性方程规定的方式演变。”</p>
<div class="note warning flat"><p>连续性方程就是一个<strong>“不作弊声明”</strong>：它保证了当我们移动每一个数据点时，整体的概率分布是连续变化的，没有概率凭空产生或消失。它是验证生成的路径是否合法的数学工具。</p>
<hr />
<p><strong>不是所有的速度场 <span class="math inline">\(v_t\)</span>
都能够生成生成合法的 <span
class="math inline">\(p_t\)</span>。（待补充）</strong></p>
</div>
<h3 id="随机微分方程sde">随机微分方程（SDE）</h3>
<h4 id="单个粒子的随机过程演变">单个粒子的随机过程演变</h4>
<p>随机微分方程的数学表达式见式 <span
class="math inline">\(\ref{eq:sde}\)</span>。 <span
class="math display">\[
\begin{equation}
\text{d}y = \underbrace{f_t \text{d}t}_{\text{漂移(确定性趋势)}} +
\underbrace{g_t \text{d}w}_{\text{扩散(随机噪声)}} \label{eq:sde}
\end{equation}
\]</span></p>
<p>这是一个粒子随时间的运动规律。我们想象一个喝醉的人走路，<span
class="math inline">\(f_t\)</span>
漂移项表示风把他往东吹（确定的力），相当于我们之前讨论过的向量场 <span
class="math inline">\(v_t\)</span>。<span class="math inline">\(g_t
\text{d}w\)</span>
扩散项表示他自己摇摇晃晃，一会儿左一会儿右（随机的力）。这个过程是随机的，每次走出来的路线都不一样。</p>
<h4 id="群体的随机过程演变">群体的随机过程演变</h4>
<p>接着上面的例子，如果我们放一万个喝醉的人在广场上，我们要描述整个人群分布（密度
<span
class="math inline">\(p_t\)</span>）是怎么变化的。这时候就不能用随机方程了，要用
<strong>Fokker-Planck 方程</strong>： <span class="math display">\[
\begin{equation}
\frac{dp_t}{dt} = \underbrace{-\text{div}(f_t p_t)}_{\text{被风吹着跑}}
+ \underbrace{\frac{g_t^2}{2}\Delta p_t}_{\text{人群慢慢散开}}
\label{eq:fokker_planck_eq}
\end{equation}
\]</span></p>
<p>第一项有 <span
class="math inline">\(\text{div}\)</span>（散度），这是我们在连续性方程里见过的，代表“流动”。第二项是
Laplace 算子 <span class="math inline">\(\Delta\)</span>（或者写作 <span
class="math inline">\(\text{div}\nabla\)</span>），它代表<strong>“扩散”</strong>。这一项让原本聚在一起的人群变“糊”了，散开了。</p>
<p>接下来，我们想把后面的 <span
class="math inline">\(\frac{g_t^2}{2}\Delta p_t\)</span>
这一项最好消灭掉。要怎么做呢？注意到（注意力惊人😅）我们有恒等式 <span
class="math inline">\(\nabla p_t = p_t \nabla \log p_t\)</span>
成立！因此， <span class="math display">\[
\frac{g_t^2}{2}\Delta p_t = \frac{g_t^2}{2}\text{div}\nabla p_t =
\frac{g_t^2}{2}\text{div} (p_t \nabla \log p_t)
\]</span></p>
<p>所以，这一项也变成了 <span class="math inline">\(\text{div}(\dots
p_t)\)</span> 的形式，我们对这两项进行合并，有 <span
class="math display">\[
\frac{dp_t}{dt} = -\text{div}\left( \left(
\underbrace{f_t}_{\text{原有的漂移}} - \underbrace{\frac{g_t^2}{2}\nabla
\log p_t}_{\text{把扩散转化成的速度}} \right) p_t \right)
\]</span></p>
<p>我们把它简写为： <span class="math display">\[
\frac{dp_t}{dt} = -\text{div}(w_t p_t)
\]</span></p>
<p>其中 <span class="math display">\[
\begin{equation}
w_t = f_t - \frac{g_t^2}{2}\nabla \log p_t \label{eq:w_t}
\end{equation}
\]</span></p>
<p>公式 <span class="math inline">\(\ref{eq:w_t}\)</span> 解释了 Flow
Matching 和扩散模型的一个核心秘密——概率流 ODE (Probability Flow
ODE)：</p>
<p>左边是一个完全确定的速度场 <span
class="math inline">\(w_t\)</span>。右边包含了原本的漂移 <span
class="math inline">\(f_t\)</span> 和 Score Function (<span
class="math inline">\(\nabla \log
p_t\)</span>)。即使原本的过程是随机的（一群醉汉乱撞），我们也能设计出一套确定的传送带（速度场
<span
class="math inline">\(w_t\)</span>），只要让醉汉站在传送带上不动，最终人群分布的形状变化，会和他们自己乱撞的效果一模一样！这就是为什么我们在训练模型时，只需要预测
Score (<span class="math inline">\(\nabla \log
p_t\)</span>)，就能构建出一个确定的 ODE
来生成图像，而不需要真的去模拟随机过程。</p>
<div class="note success flat"><p>🤔<strong>个人理解</strong></p>
<hr />
<p>这一部分我个人的理解就是，虽然单个粒子的演变是随机的。但是，当粒子数足够多的时候，粒子云整体反映出来的宏观性质却是确定性的，因为整个的
<span class="math inline">\(\ref{eq:fokker_planck_eq}\)</span>
公式的两边都没有任何的随机项。这就是<strong>群体的确定性</strong>。</p>
<p>因此，既然宏观云团的演变是确定的，那我们可以不要那些乱跑的醉汉。我们可以设计一种“传送带”（确定性的速度场
<span
class="math inline">\(v_t\)</span>），让粒子乖乖地沿着传送带走（不乱跑，去掉了
<span class="math inline">\(dw\)</span>）。只要传送带设计得好（符合公式
40），这些乖乖走的粒子形成的云团形状，就会和那些醉汉乱跑形成的云团形状一模一样。</p>
</div>
<h2 id="连续归一化流">连续归一化流</h2>
<p>连续归一化流的作用就是给定一个简单的先验分布（simple prior density）
<span class="math inline">\(p_0\)</span>（例如纯噪声），通过 <span
class="math inline">\(\phi_t\)</span> 的映射，转变成一个复杂的分布 <span
class="math inline">\(p_t\)</span>。push_forward equation 如式 <span
class="math inline">\(\ref{eq:push_forward_eq}\)</span>。 <span
class="math display">\[
\begin{equation}
p_t = \left[ \phi_t \right]_*p_0 \label{eq:push_forward_eq}
\end{equation}
\]</span></p>
<p>其中前推算子/变量变换算子 <span class="math inline">\(*\)</span>
定义如式 <span
class="math inline">\(\ref{eq:push_forward_eq_def}\)</span>。 <span
class="math display">\[
\begin{equation}
p_t(x) = [\phi_t]_* p_0(x) = p_0(\phi_t^{-1}(x)) \det \left[
\frac{\partial \phi_t^{-1}}{\partial x}(x) \right]
\label{eq:push_forward_eq_def}
\end{equation}
\]</span></p>
<h3 id="补充变量变换公式的推导过程">补充变量变换公式的推导过程</h3>
<p>不妨假设原始随机变量 <span class="math inline">\(x_0\)</span> 经过了
<span class="math inline">\(\phi_t\)</span>
变换函数的映射，变成了新的变量 <span
class="math inline">\(x_1\)</span>。于是，我们的目标是，知道了 <span
class="math inline">\(x_0\)</span> 的概率分布 <span
class="math inline">\(p_0\)</span>，如何得到 <span
class="math inline">\(x_1\)</span> 的概率分布 <span
class="math inline">\(p_1\)</span>。</p>
<p>由概率守恒公式 <span class="math display">\[
\begin{equation}
p_0(x_0)dx_0 = p_1(x_1)dx_1
\end{equation}
\]</span></p>
<p>可以有 <span class="math display">\[
\begin{equation}
\Rightarrow p_1(x) = p_0(x_0) \cdot \frac{d x_0}{d x_1}
\end{equation}
\]</span></p>
<p>再将其推广到高维空间，有 <span class="math display">\[
p_1(x) = p_0(x_0) \cdot \left| \det \left( \frac{\partial x_0}{\partial
x_1} \right) \right|
\]</span></p>
<p>因为 <span class="math inline">\(x_0 =
\phi^{-1}(x)\)</span>，将其带入后就得到了 <span
class="math inline">\(\ref{eq:push_forward_eq_def}\)</span>
公式了。这说明了这样一件事：当我们想知道 <span
class="math inline">\(x_1\)</span> 的概率分布 <span
class="math inline">\(p_1\)</span>，首先，我们需要先用逆函数，将 <span
class="math inline">\(x\)</span> 变为 <span
class="math inline">\(x_0\)</span>，算出那个位置原来的概率密度 <span
class="math inline">\(p_0\)</span>。之后，使用雅可比矩阵的行列式，作为体积压缩倍数，就能算出位置的当前的概率密度
<span class="math inline">\(p_1\)</span>。</p>
<h3 id="几个重要量之间的关系">几个重要量之间的关系</h3>
<ol type="1">
<li>流 <span class="math inline">\(\phi_t(x)\)</span></li>
<li>场 <span class="math inline">\(v_t\)</span></li>
<li>概率密度 <span class="math inline">\(p_0 \rightarrow
p_t\)</span></li>
</ol>
<ul>
<li><strong>从流 <span class="math inline">\(\phi_t(x)\)</span> 到场
<span class="math inline">\(v_t\)</span> 的变换：</strong>可以参考公式
<span class="math inline">\(\ref{eq:vt}\)</span> 和 <span
class="math inline">\(\ref{eq:flow_def2}\)</span>。其中，<span
class="math inline">\(\ref{eq:vt}\)</span> 说明了场 <span
class="math inline">\(v_t\)</span> 是流 <span
class="math inline">\(\phi_t(x)\)</span> 的微分，反过来，流 <span
class="math inline">\(\phi_t(x)\)</span> 是场 <span
class="math inline">\(v_t\)</span> 的积分。</li>
<li><strong>从 <span class="math inline">\(p_0\)</span> 到 <span
class="math inline">\(p_t\)</span> 的变换：</strong>：可以参考公式 <span
class="math inline">\(\ref{eq:push_forward_eq_def}\)</span>。这个公式说明了当我们想知道
<span class="math inline">\(x_1\)</span> 的概率分布 <span
class="math inline">\(p_1\)</span>，首先，我们需要先用逆函数，将 <span
class="math inline">\(x\)</span> 变为 <span
class="math inline">\(x_0\)</span>，算出那个位置原来的概率密度 <span
class="math inline">\(p_0\)</span>。之后，使用雅可比矩阵的行列式，作为体积压缩倍数，就能算出位置的当前的概率密度
<span class="math inline">\(p_1\)</span>。</li>
<li><strong>从场 <span class="math inline">\(v_t\)</span> 到概率密度
<span class="math inline">\(p_t\)</span> 的变换：</strong>可以参考公式
<span
class="math inline">\(\ref{eq:continuity_eq}\)</span>。这个公式说明了概率密度的变化与场
<span class="math inline">\(v_t\)</span> 变化之间的关系。当 <span
class="math inline">\(v_t\)</span>
的方向向周围散开，当前位置的概率密度就会变低，反之，则会变高。</li>
</ul>
<h2 id="流匹配目标">流匹配目标</h2>
<h3 id="符号定义">符号定义</h3>
<ul>
<li><span class="math inline">\(x_1 \sim
q(x_1)\)</span>：这是真实数据（比如真实的人脸图片），这在我们训练过程中作为样本数据，其分布未知。</li>
<li><span class="math inline">\(p_t\)</span>：这是概率路径 (Probability
Path)。也就是从噪声变成数据的过程中，中间每一时刻的分布长什么样。</li>
<li><span class="math inline">\(p_0 =
p\)</span>：这是初始分布，一般来说就是简单的分布，比如标准正态分布（噪声）。</li>
</ul>
<p>我们的任务就是想办法把简单的 <span class="math inline">\(p_0\)</span>
变成复杂的 <span class="math inline">\(q(x_1)\)</span>。</p>
<h3 id="流匹配的目标公式">流匹配的目标公式</h3>
<p>假设我们已经有了一个完美的概率路径 <span
class="math inline">\(p_t(x)\)</span>，那么一定存在一个对应的向量场
<span
class="math inline">\(u_t(x)\)</span>，它能驱动这个路径的演变（生成
<span class="math inline">\(p_t\)</span>），那么这个向量场 <span
class="math inline">\(u_t(x)\)</span> 就是我们想要得到的。而 <span
class="math inline">\(p_t(x) \leftrightarrow
u_t(x)\)</span>，也就是说如果上帝视角已经告诉了我们路径 <span
class="math inline">\(p_t\)</span>，那对应的速度场 <span
class="math inline">\(u_t\)</span>
也就是确定的了。我们想要构建一个神经网络，其参数为 <span
class="math inline">\(\theta\)</span>，模型的输出为 <span
class="math inline">\(v_t(x)\)</span>。流匹配的目标，就是<strong>让神经网络预测的向量场
<span class="math inline">\(v_t\)</span>，去尽可能逼近 (Regress)
那个完美的向量场 <span
class="math inline">\(u_t\)</span></strong>。我们使用一个简单的均方误差进行逼近，用公式写出来就是
<span class="math inline">\(\ref{eq:fm_objective}\)</span>。</p>
<p><span class="math display">\[
\begin{equation}
\mathcal{L}_{FM}(\theta) = \mathbb{E}_{t, p_t(x)} || v_t(x) - u_t(x)
||^2 \label{eq:fm_objective}
\end{equation}
\]</span></p>
<h3 id="面临的问题">面临的问题</h3>
<p>公式 <span class="math inline">\(\ref{eq:fm_objective}\)</span>
面临一个严重的问题就是我们事先不知道 <span
class="math inline">\(p_t\)</span> 和 <span
class="math inline">\(u_t\)</span>。我们只有头（噪声 <span
class="math inline">\(p_0\)</span>）和尾（真图 <span
class="math inline">\(p_1\)</span>），中间到底该怎么走（<span
class="math inline">\(p_t\)</span>）？中间的速度到底是多少（<span
class="math inline">\(u_t\)</span>）？我们是不知道的！如果我们不知道标准答案
<span class="math inline">\(u_t\)</span>，怎么去训练网络 <span
class="math inline">\(v_t\)</span> 呢？</p>
<div class="note success flat"><p>Diffusion
是通过“逐步加噪”（固定好的正态分布变换）<strong>强行定义了中间的 <span
class="math inline">\(p_t\)</span></strong>，所以它知道中间长什么样。</p>
</div>
<p>为了解决这个问题，下一节的内容将会给出两种解决思路：<strong>给出
<span class="math inline">\(u_t\)</span>
形式</strong>或者<strong>创建一个更易实现的流目标</strong></p>
<h2
id="通过条件概率路径和向量场构建-p_t-和-u_t">通过条件概率路径和向量场构建
<span class="math inline">\(p_t\)</span> 和 <span
class="math inline">\(u_t\)</span></h2>
<h3 id="构建-p_t">构建 <span class="math inline">\(p_t\)</span></h3>
<h4 id="条件概率路径">条件概率路径</h4>
<p>一个简单的构造复杂概率路径的方法是通过混合一系列的更简单的概率路径。如果给定了一个样本数据
<span class="math inline">\(x_1\)</span>，我们定义 <span
class="math inline">\(p_t(x | x_1)\)</span>
叫做条件概率路径，如果它满足两个条件：</p>
<ul>
<li><span class="math inline">\(t = 0\)</span> 时，<span
class="math inline">\(p_0(x | x_1) = p(x)\)</span>；</li>
<li><span class="math inline">\(t = 1\)</span> 时，<span
class="math inline">\(p_1(x | x_1) = \mathcal{N}(x; x_1,
\sigma^2I)\)</span>，其中 <span class="math inline">\(\sigma\)</span>
是一个足够小的正值。</li>
</ul>
<div class="note danger flat"><p><span class="math inline">\(\sigma\)</span>
是一个足够小的正值保证了这个高斯函数类似于一个脉冲函数，只在 <span
class="math inline">\(x = x_1\)</span>
的时候取一个很大的数，其他地方的取值很小很小。</p>
</div>
<p>通过对条件概率路径的边缘化，可以得到边缘概率路径 <span
class="math inline">\(\ref{eq:marginal_prob_path}\)</span>。 <span
class="math display">\[
\begin{equation}
p_t(x) = \int p_t(x | x_1)q(x_1) \text{d}x_1
\label{eq:marginal_prob_path}
\end{equation}
\]</span></p>
<div class="note success flat"><p>🤯这个公式 <span
class="math inline">\(\ref{eq:marginal_prob_path}\)</span>
其实就是概率论中的全概率公式的连续化版本。表达的是 <span
class="math inline">\(x\)</span> 的概率，就是在不同的 <span
class="math inline">\(x_i\)</span> 下的条件分布，去乘上 <span
class="math inline">\(x_i\)</span>
各自出现的概率，最终汇总就有了（只要有） <span
class="math inline">\(x\)</span> 出现的概率。</p>
</div>
<p>当 <span class="math inline">\(t = 0\)</span> 的时候，不难证明 <span
class="math inline">\(p_0(x) =
p(x)\)</span>，也就是初始的时候的数据的分布是一个简单分布。 <span
class="math display">\[
\begin{align}
p_0(x) &amp;= \int p_0(x | x_1)q(x_1) \text{d}x_1 \\
&amp;= \int p(x)q(x_1) \text{d}x_1 \\
&amp;= p(x)\int q(x_1) \text{d}x_1 \\
&amp;= p(x)
\end{align}
\]</span></p>
<p>接下来，我们需要证明 <span class="math inline">\(t = 1\)</span>
的时候，<span class="math inline">\(p_1(x) =
q(x)\)</span>，也就是最终的分布是真实的数据的分布。</p>
<h4 id="狄拉克函数">狄拉克函数</h4>
<h5 id="公式表达">公式表达</h5>
<p>首先，我们需要对狄拉克 <span class="math inline">\(\delta\)</span>
函数 (Dirac Delta Function) 进行一下补充。狄拉克函数的定义如式 <span
class="math inline">\(\ref{eq:dirac_func}\)</span>。 <span
class="math display">\[
\begin{equation}
\delta(x) = \begin{cases} +\infty &amp; x=0 \\ 0 &amp; x \neq 0
\end{cases} \label{eq:dirac_func}
\end{equation}
\]</span></p>
<h5 id="积分面积性质">积分（面积）性质</h5>
<p>这意味着狄拉克函数在原点 <span class="math inline">\(x=0\)</span>
处无限高，而在其他任何地方都是
0。虽然它无限细、无限高，但它围成的“面积”被强行定义为 1，即公式 <span
class="math inline">\(\ref{eq:dirac_func_int}\)</span>。 <span
class="math display">\[
\begin{equation}
\int_{-\infty}^{+\infty} \delta(x) dx = 1 \label{eq:dirac_func_int}
\end{equation}
\]</span></p>
<h5 id="筛选性质">筛选性质</h5>
<p>筛选性质是这个函数最有用的地方，公式表达为 <span
class="math display">\[
\int_{-\infty}^{\infty} f(x) \delta(x-a) dx = f(a)
\]</span></p>
<p><span class="math inline">\(\delta(x-a)\)</span>
是把狄拉克函数的脉冲的“尖刺”从原点移到了 <span
class="math inline">\(x=a\)</span> 的位置。当我们拿任何函数 <span
class="math inline">\(f(x)\)</span>
去乘以这个尖刺并积分时，积分的结果就像是一只手，只把 <span
class="math inline">\(x=a\)</span> 那个位置的函数值 <span
class="math inline">\(f(a)\)</span>
给“抓”了出来，其他部分的信息全被扔掉了（因为乘以了 0）。</p>
<p>参照这个思路的证明过程如下所示： <span class="math display">\[
\begin{align}
\int_{-\infty}^{\infty} f(x) \delta(x-a) dx &amp;=
\int_{-\infty}^{\infty} f(a) \delta(x-a) \\
&amp;= f(a) \int_{-\infty}^{\infty} \delta(x-a) \\
&amp;= f(a)
\end{align}
\]</span></p>
<p>回到本问题，因为我们规定了 <span class="math inline">\(p_1(x | x_1) =
\mathcal{N}(x; x_1, \sigma^2I)\)</span>，并且高斯分布的均值为 <span
class="math inline">\(x_1\)</span>，方差为 <span
class="math inline">\(\sigma^2\)</span> 且 <span
class="math inline">\(\sigma\)</span>
是一个足够小的正值。那么如果把这个高斯分布的图像画一下，可以发现它其实也是近似于一个狄拉克函数的。并且，其“尖刺”是位于
<span class="math inline">\(x = x_1\)</span>
均值这个地方。这样一来，</p>
<p><span class="math display">\[
\begin{align}
p_1(x) &amp;= \int p_1(x | x_1)q(x_1) \text{d}x_1 \\
&amp;= \int \delta^*(x - x_1) q(x_1) \text{d}x_1 \\
&amp;\approx q(x) \int \delta^*(x - x_1) \text{d}x_1 \\
&amp;\approx q(x)
\end{align}
\]</span></p>
<p>注意上面式子中是对 <span class="math inline">\(x_1\)</span>
进行积分，只有当 <span class="math inline">\(x_1 = x\)</span>
的时候，高斯分布才会有一个很大的值，其余位置都取极小的数值，因此可以近似为一个狄拉克函数，在公式中我们记为了
<span
class="math inline">\(\delta^*\)</span>。也正是因为只是近似狄拉克函数，所以最后这里是取约等于号
<span class="math inline">\(\approx\)</span> 而非严格相等。</p>
<div class="note danger flat"><p>🧐<strong>为什么设置 <span class="math inline">\(t = 1\)</span>
为高斯分布？</strong></p>
<hr />
<p>EDM p22（待补充）</p>
</div>
<h3 id="构建-u_t">构建 <span class="math inline">\(u_t\)</span></h3>
<p>在前面一小节我们已经构造出了 <span class="math inline">\(p_t(x |
x_1)\)</span> 和 <span class="math inline">\(p_t(x)\)</span>
的表达式了。现在，让我们用连续性方程 <span
class="math inline">\(\ref{eq:continuity_eq}\)</span> 来求解得到 <span
class="math inline">\(u_t(x | x_1)\)</span>。由边缘化场向量，可以得到
<span class="math inline">\(u_t(x)\)</span> 的形式，见公式 <span
class="math inline">\(\ref{eq:marginal_vec_field}\)</span>。我们的目标任务是，证明此时的
<span class="math inline">\(p_t(x)\)</span> 和 <span
class="math inline">\(u_t(x)\)</span>，也是满足连续性方程 <span
class="math inline">\(\ref{eq:continuity_eq}\)</span>的。</p>
<p><span class="math display">\[
\begin{equation}
u_t(x) = \int u_t(x | x_1) \frac{p_t(x | x_1)q(x_1)}{p_t(x)} \text{d}
x_1 \label{eq:marginal_vec_field}
\end{equation}
\]</span></p>
<div class="note info flat"><p><strong>梳理一下现在我们得到的信息</strong></p>
<hr />
<p>已知信息：<span class="math inline">\(p_t(x | x_1)\)</span> 和 <span
class="math inline">\(p_t(x)\)</span>，以及这两个概率路径之间的关系式
<span
class="math inline">\(\ref{eq:marginal_prob_path}\)</span>，且通过连续性方程得到了
<span class="math inline">\(u_t(x | x_1)\)</span>。 求解目标：<span
class="math inline">\(u_t(x)\)</span>，且 <span
class="math inline">\(u_t(x)\)</span> 和其对应的 <span
class="math inline">\(p_t(x)\)</span> 需要满足连续性方程。</p>
</div>
<p>推导一下公式 <span
class="math inline">\(\ref{eq:marginal_vec_field}\)</span>
是怎么得来的： <span class="math display">\[
\begin{align}
\frac{d}{dt}p_t(x) &amp;= \int
\left(\frac{d}{dt}p_t(x|x_1)\right)q(x_1)dx_1 \quad \text{（$p_t$ 对时间
$t$ 进行求导）}\\
&amp;= -\int \text{div}\left(u_t(x|x_1)p_t(x|x_1)\right)q(x_1)dx_1 \quad
\text{（代入 $p_t(x|x_1)$ 和 $u_t(x|x_1)$ 的连续性方程）}\\
&amp;= -\text{div}\left(\int u_t(x|x_1)p_t(x|x_1)q(x_1)dx_1\right) \quad
\text{（交换 div 和 $\int$ 的顺序）} \\
&amp;= -\text{div}\left(p_t(x) \underbrace{\int
\frac{u_t(x|x_1)p_t(x|x_1)q(x_1)}{p_t(x)}dx_1}_{u_t(x)}\right) \quad
\text{（$1 = \frac{p_t(x)}{p_t(x)}$）} \\
&amp;= -\text{div}\left(u_t(x)p_t(x)\right)
\end{align}
\]</span></p>
<p>注意 <span class="math inline">\(\text{div}\)</span> 是对 <span
class="math inline">\(x\)</span> 进行求导然后求和，而 <span
class="math inline">\(\int\)</span> 则是对 <span
class="math inline">\(x_1\)</span>
进行积分，两者作用的变量不同，可以认为是独立的，因此可以交换 <span
class="math inline">\(\text{div}\)</span> 和 <span
class="math inline">\(\int\)</span> 的顺序，且在 <span
class="math inline">\(\int\)</span> 内进行任何对于 <span
class="math inline">\(x\)</span> 的操作不会影响等式的成立。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://Ardbr.github.io">creat</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://ardbr.github.io/2026/02/12/notes/flow_matching/flow-matching-Ch01/">https://ardbr.github.io/2026/02/12/notes/flow_matching/flow-matching-Ch01/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://Ardbr.github.io" target="_blank">creat's HomePage</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flow-Matching/">Flow Matching</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.gif" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2026/02/14/notes/flow_matching/flow-matching-Ch02/" title="flow_matching Ch02"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">flow_matching Ch02</div></div><div class="info-2"><div class="info-item-1">条件流匹配（CFM） 在上一章节中，最后我们给出了边缘概率路径 \(\ref{eq:marginal_prob_path}\) 和边缘场向量 \(\ref{eq:marginal_vec_field}\) 的公式表达。 \[ \begin{align} p_t(x) &amp;= \int p_t(x | x_1)q(x_1) \text{d}x_1 \label{eq:marginal_prob_path} \\ u_t(x) &amp;= \int u_t(x | x_1) \frac{p_t(x | x_1)q(x_1)}{p_t(x)} \text{d} x_1 \label{eq:marginal_vec_field} \end{align} \] 然而，这两个公式都存在一个共同的问题：需要计算积分。积分是不好计算的，这也导致了计算原流匹配目标 \(\ref{eq:original_fm_objective}\)难以计算。 \[ \begin{equation} \mathcal{L}_\text{FM}(\theta) = \mathbb{E}_{t,...</div></div></div></a><a class="pagination-related" href="/2026/02/11/notes/diffusion/diffusion-Ch03/" title="diffusion Ch03"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">diffusion Ch03</div></div><div class="info-2"><div class="info-item-1">条件扩散模型 至此，我们研究的都只是简单的分布 \(p(\boldsymbol{x})\)，然而，在实际应用中，我们经常会对形如 \(p(\boldsymbol{x} | y)\) 这种有条件的分布更感兴趣。这样一来，我们就可以通过条件 \(y\) 来对生成的数据 \(\boldsymbol{x}\) 进行控制。例如，在 image-text 生成模型中，\(y\) 就可以被视作对于输入文本 text 的编码。 回忆我们之前的联合概率密度公式 \[ \begin{equation} p(\boldsymbol{x}_{0:T}) = p(\boldsymbol{x}_T) \prod_{t=1}^{T} p_{\theta}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t) \label{eq:dist_uncond} \end{equation} \] 我们在分布 \(p(\cdot)\) 中注入条件 \(y\)，即 \(p(\cdot | y)\)，公式 \(\ref{eq:dist_uncond}\) 就会转变成...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2026/02/22/notes/reinforcement_learning/reinforcement-learning-Ch01/" title="reinforcement_learning Ch01"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-22</div><div class="info-item-2">reinforcement_learning Ch01</div></div><div class="info-2"><div class="info-item-1"> </div></div></div></a><a class="pagination-related" href="/2026/02/14/notes/flow_matching/flow-matching-Ch02/" title="flow_matching Ch02"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-14</div><div class="info-item-2">flow_matching Ch02</div></div><div class="info-2"><div class="info-item-1">条件流匹配（CFM） 在上一章节中，最后我们给出了边缘概率路径 \(\ref{eq:marginal_prob_path}\) 和边缘场向量 \(\ref{eq:marginal_vec_field}\) 的公式表达。 \[ \begin{align} p_t(x) &amp;= \int p_t(x | x_1)q(x_1) \text{d}x_1 \label{eq:marginal_prob_path} \\ u_t(x) &amp;= \int u_t(x | x_1) \frac{p_t(x | x_1)q(x_1)}{p_t(x)} \text{d} x_1 \label{eq:marginal_vec_field} \end{align} \] 然而，这两个公式都存在一个共同的问题：需要计算积分。积分是不好计算的，这也导致了计算原流匹配目标 \(\ref{eq:original_fm_objective}\)难以计算。 \[ \begin{equation} \mathcal{L}_\text{FM}(\theta) = \mathbb{E}_{t,...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.gif" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">creat</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ardbr"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Ardbr" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">希望每天都能输出一点新知识😌</div></div><div class="card-widget card-countdown"><div class="countdown-mask"><div class="text-container"><p>2026 年已经过去</p><span class="countdown-number">xx</span><span class="countdown-unit">天</span></div><div class="current-time-container"> <span class="current-time"></span></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#flow-matching-%E6%80%BB%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">Flow Matching 总览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9B%AE%E6%A0%87"><span class="toc-number">1.1.</span> <span class="toc-text">生成模型的目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%9A%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">做法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E7%A7%8D%E6%B1%82%E8%A7%A3%E8%B7%AF%E5%BE%84"><span class="toc-number">1.3.</span> <span class="toc-text">两种求解路径</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#normalizing-flow%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81"><span class="toc-number">1.3.1.</span> <span class="toc-text">Normalizing Flow（标准化流）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#flow-matching%E6%B5%81%E5%8C%B9%E9%85%8D"><span class="toc-number">1.3.2.</span> <span class="toc-text">Flow Matching（流匹配）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flow-%E5%AE%9A%E4%B9%89"><span class="toc-number">2.</span> <span class="toc-text">Flow 定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E8%A7%82%E8%A7%86%E8%A7%92%E5%BE%AE%E5%88%86v_t"><span class="toc-number">2.1.</span> <span class="toc-text">微观视角（微分）——\(v_t\)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8F%E8%A7%82%E8%A7%86%E8%A7%92%E7%A7%AF%E5%88%86phi"><span class="toc-number">2.2.</span> <span class="toc-text">宏观视角（积分）——\(\phi\)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E7%9A%84%E7%AD%89%E4%BB%B7%E5%85%B3%E7%B3%BB"><span class="toc-number">2.3.</span> <span class="toc-text">两者的等价关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">连续性方程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E5%85%AC%E5%BC%8F%E8%A1%A8%E8%BE%BE"><span class="toc-number">3.1.</span> <span class="toc-text">连续性方程公式表达</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90%E7%90%86%E8%A7%A3"><span class="toc-number">3.2.</span> <span class="toc-text">例子理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">3.3.</span> <span class="toc-text">连续性方程的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8Bsde"><span class="toc-number">3.4.</span> <span class="toc-text">随机微分方程（SDE）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA%E7%B2%92%E5%AD%90%E7%9A%84%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E6%BC%94%E5%8F%98"><span class="toc-number">3.4.1.</span> <span class="toc-text">单个粒子的随机过程演变</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BE%A4%E4%BD%93%E7%9A%84%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E6%BC%94%E5%8F%98"><span class="toc-number">3.4.2.</span> <span class="toc-text">群体的随机过程演变</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E5%BD%92%E4%B8%80%E5%8C%96%E6%B5%81"><span class="toc-number">4.</span> <span class="toc-text">连续归一化流</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%E5%8F%98%E9%87%8F%E5%8F%98%E6%8D%A2%E5%85%AC%E5%BC%8F%E7%9A%84%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text">补充变量变换公式的推导过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E9%87%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">4.2.</span> <span class="toc-text">几个重要量之间的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%81%E5%8C%B9%E9%85%8D%E7%9B%AE%E6%A0%87"><span class="toc-number">5.</span> <span class="toc-text">流匹配目标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%A6%E5%8F%B7%E5%AE%9A%E4%B9%89"><span class="toc-number">5.1.</span> <span class="toc-text">符号定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E5%8C%B9%E9%85%8D%E7%9A%84%E7%9B%AE%E6%A0%87%E5%85%AC%E5%BC%8F"><span class="toc-number">5.2.</span> <span class="toc-text">流匹配的目标公式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%A2%E4%B8%B4%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">5.3.</span> <span class="toc-text">面临的问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E8%B7%AF%E5%BE%84%E5%92%8C%E5%90%91%E9%87%8F%E5%9C%BA%E6%9E%84%E5%BB%BA-p_t-%E5%92%8C-u_t"><span class="toc-number">6.</span> <span class="toc-text">通过条件概率路径和向量场构建
\(p_t\) 和 \(u_t\)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA-p_t"><span class="toc-number">6.1.</span> <span class="toc-text">构建 \(p_t\)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E8%B7%AF%E5%BE%84"><span class="toc-number">6.1.1.</span> <span class="toc-text">条件概率路径</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8B%84%E6%8B%89%E5%85%8B%E5%87%BD%E6%95%B0"><span class="toc-number">6.1.2.</span> <span class="toc-text">狄拉克函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F%E8%A1%A8%E8%BE%BE"><span class="toc-number">6.1.2.1.</span> <span class="toc-text">公式表达</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A7%AF%E5%88%86%E9%9D%A2%E7%A7%AF%E6%80%A7%E8%B4%A8"><span class="toc-number">6.1.2.2.</span> <span class="toc-text">积分（面积）性质</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AD%9B%E9%80%89%E6%80%A7%E8%B4%A8"><span class="toc-number">6.1.2.3.</span> <span class="toc-text">筛选性质</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA-u_t"><span class="toc-number">6.2.</span> <span class="toc-text">构建 \(u_t\)</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/22/notes/reinforcement_learning/reinforcement-learning-Ch01/" title="reinforcement_learning Ch01">reinforcement_learning Ch01</a><time datetime="2026-02-22T09:17:33.552Z" title="更新于 2026-02-22 17:17:33">2026-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/14/notes/flow_matching/flow-matching-Ch02/" title="flow_matching Ch02">flow_matching Ch02</a><time datetime="2026-02-22T09:09:27.296Z" title="更新于 2026-02-22 17:09:27">2026-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/15/notes/diffusion/diffusion-Ch04/" title="diffusion Ch04">diffusion Ch04</a><time datetime="2026-02-15T15:08:41.405Z" title="更新于 2026-02-15 23:08:41">2026-02-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/notes/flow_matching/flow-matching-Ch01/" title="flow_matching Ch01">flow_matching Ch01</a><time datetime="2026-02-15T02:43:06.395Z" title="更新于 2026-02-15 10:43:06">2026-02-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/11/notes/diffusion/diffusion-Ch03/" title="diffusion Ch03">diffusion Ch03</a><time datetime="2026-02-15T02:42:57.148Z" title="更新于 2026-02-15 10:42:57">2026-02-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2026 By creat</div><div class="footer_custom_text">很高兴你能看到这里！</div></div></footer></div><div id="leftside-fps"><span id="leftside-fps-text"></span></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'ams',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }
      
      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script src=/js/sakuraPlus.js></script><script src=/js/parseLyric.js></script><script src=/js/music.js></script><script src=/js/getFps.js></script><script src=/js/countdown.js></script><script src=/js/mathjax.js></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      pjax.loadUrl('/404.html')
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>